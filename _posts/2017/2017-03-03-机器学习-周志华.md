---
layout: post
title: 机器学习-读书笔记
category: 
- ML
tags:
- records
---

#### 集成学习
1. 如何发现弱学习算法？  
  
2. adaboost   
- 弱分类器的系数是怎么计算出的，为什么要这样计算？目的：最小化**指数损失函数**  
- 迭代生成弱分类器过程中错误率大于0.5，break 之后怎么办？？？--->>抛弃当前的基学习器  
- 指数损失函数与0-1损失函数效果一致的**证明**
- 每次新分类器系数得到的方法-->使得最小化指数损失函数（因为总分类器是加权和，所以可以这样做）
- zm 怎么推导出的，watermelon，P176，最后一步
- 不需要知道下界？？，下界为零？？，lihangP143

#### Bagging与随机森林
1. 如果采样出的每个子集都完全不同，每个基学习器都只用到一小部分训练数据，便不能进行有效的学习--->> 特定类型样本的预测不能通过不同的基学习器共同作用来实现，也就失去了提升（boost）的目的，--->> 采用相互有交叠的采样子集，（但是为了体现差异，又不能交叠太多！！-->> 如何把握**?**）
2. **63.2%** ?? -->  如何按照需求调整？重复的怎么办？

